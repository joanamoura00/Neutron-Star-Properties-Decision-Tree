{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K_sat</th>\n",
       "      <th>Q_sat</th>\n",
       "      <th>Z_sat</th>\n",
       "      <th>E_sym</th>\n",
       "      <th>L_sym</th>\n",
       "      <th>K_sym</th>\n",
       "      <th>Q_sym</th>\n",
       "      <th>Z_sym</th>\n",
       "      <th>R10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227.171398</td>\n",
       "      <td>88.768968</td>\n",
       "      <td>-179.115601</td>\n",
       "      <td>28.109773</td>\n",
       "      <td>70.713317</td>\n",
       "      <td>-176.966916</td>\n",
       "      <td>224.419874</td>\n",
       "      <td>656.524971</td>\n",
       "      <td>12.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232.589005</td>\n",
       "      <td>132.098105</td>\n",
       "      <td>-167.056538</td>\n",
       "      <td>32.743075</td>\n",
       "      <td>85.060572</td>\n",
       "      <td>-114.273255</td>\n",
       "      <td>-84.254912</td>\n",
       "      <td>730.292564</td>\n",
       "      <td>12.701489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210.963869</td>\n",
       "      <td>351.461450</td>\n",
       "      <td>-523.245991</td>\n",
       "      <td>33.692041</td>\n",
       "      <td>49.685094</td>\n",
       "      <td>-87.522249</td>\n",
       "      <td>237.409814</td>\n",
       "      <td>-208.489208</td>\n",
       "      <td>12.404865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244.329171</td>\n",
       "      <td>157.304519</td>\n",
       "      <td>-286.615934</td>\n",
       "      <td>33.500592</td>\n",
       "      <td>53.203060</td>\n",
       "      <td>4.410613</td>\n",
       "      <td>-113.367538</td>\n",
       "      <td>218.245650</td>\n",
       "      <td>12.579676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185.028601</td>\n",
       "      <td>153.106499</td>\n",
       "      <td>-247.680638</td>\n",
       "      <td>34.209498</td>\n",
       "      <td>73.918805</td>\n",
       "      <td>-139.897289</td>\n",
       "      <td>-51.679093</td>\n",
       "      <td>918.078659</td>\n",
       "      <td>12.260222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        K_sat       Q_sat       Z_sat      E_sym      L_sym       K_sym  \\\n",
       "0  227.171398   88.768968 -179.115601  28.109773  70.713317 -176.966916   \n",
       "1  232.589005  132.098105 -167.056538  32.743075  85.060572 -114.273255   \n",
       "2  210.963869  351.461450 -523.245991  33.692041  49.685094  -87.522249   \n",
       "3  244.329171  157.304519 -286.615934  33.500592  53.203060    4.410613   \n",
       "4  185.028601  153.106499 -247.680638  34.209498  73.918805 -139.897289   \n",
       "\n",
       "        Q_sym       Z_sym        R10  \n",
       "0  224.419874  656.524971  12.600000  \n",
       "1  -84.254912  730.292564  12.701489  \n",
       "2  237.409814 -208.489208  12.404865  \n",
       "3 -113.367538  218.245650  12.579676  \n",
       "4  -51.679093  918.078659  12.260222  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading our csv data\n",
    "dados = pd.read_csv('dados 40k.csv')\n",
    "\n",
    "X = dados.drop('R10', axis=1)\n",
    "\n",
    "target_column = ['R10'] #criar a coluna target para o y\n",
    "predictors = list(set(list(dados.columns))-set(target_column)) #retirar a coluna target e ficar apenas com as features, x\n",
    "#dados[predictors] = dados[predictors]/dados[predictors].max() #normalização das unidades, outra forma não utilizada\n",
    "\n",
    "#dados.describe()\n",
    "\n",
    "#criar o conjunto de dados de treino e de teste, pois não estavam em colunas\n",
    "X = dados[predictors].values\n",
    "y = dados[target_column].values\n",
    "\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, depois de importar os dados utilizando o comando pd.read_csv, separaram-se os dados relativos ao raio, o nosso y, que será a coluna alvo. Todas as restantes colunas serão os vários parâmetros x, que servirão para prever o y. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, com os dados importados, podemos Scomeçar os vários métodos de treino e teste para implementar as Decision Trees.\n",
    "Nesta primeira fase, pretendeu-se construir uma decision tree, sem a otimização dos parâmetros da função DecisionTreeRegressor, com o objetivo de estudar o efeito da otimização dos mesmos nos resultados finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15635235, -0.52888439,  0.71890326, ...,  1.35769258,\n",
       "        -1.67479256, -0.30648178],\n",
       "       [ 0.49170312, -1.19248019,  0.93154557, ..., -1.20557815,\n",
       "         0.75025959,  1.31831765],\n",
       "       [-1.99354553, -1.04921926,  0.81499513, ..., -1.70420204,\n",
       "         0.87983944, -0.42627916],\n",
       "       ...,\n",
       "       [ 0.1134122 , -0.52916423,  0.66332793, ...,  0.73199616,\n",
       "         1.88253035, -0.25065537],\n",
       "       [-0.17832715,  0.84337274, -0.44726764, ..., -0.53026409,\n",
       "         0.28388689, -0.02901212],\n",
       "       [ 0.17133019, -0.20083147,  0.13072011, ...,  0.42457065,\n",
       "        -0.65152104,  1.01742252]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É de notar que antes de proceder a qualquer implementação do modelo, é necessária uma normalização às unidades de todos os dados. Para isto, usou-se a função StandardScaler, que normaliza as propriedades colocadas na função, subtraindo às amostras a média e escalonando-se relativamente à variância da unidade. O resultado aproximar-se-á a uma distribuição normal gaussiana centrada em 0 e com variância igual à unidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tamanho do conjunto de dados de treino\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tamanho do conjunto de dados de teste\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extra: encontrar valores, parâmetros cuja importância é maior para o modelo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "#aqui o split está feito de outra forma para testar \n",
    "X_train, X_test, y_train, y_test = train_test_split(dados.iloc[:,:-1], dados.iloc[:,-1], test_size = 0.25, random_state = 0)\n",
    "\n",
    "extra = ExtraTreesRegressor() #classe: encontra os parâmetros mais importantes\n",
    "\n",
    "extra.fit(X_train,y_train)\n",
    "\n",
    "#print da importância dos parâmetros\n",
    "extra.feature_importances_\n",
    "\n",
    "feat_importances = pd.Series(extra.feature_importances_, index = X_train.columns) #a função Series apenas aceita colunas\n",
    "feat_importances.nlargest(8).plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para além da implementação do modelo, é importante estudar a importância, o peso de cada parâmetro, no cálculo do valor do raio R10. Assim, procedeu-se a um split, para formar conjuntos de dados de teste e de treino e usou-se a classe ExtraTreesRegressor. Esta classe encontra os parâmetros mais importantes, implementando um estimador meta que ajusta decision trees aleatórias, extra-trees, a várias sub-amostras dos dados. Usa médias para otimizar a eficácia da previsão e o controlo de over-fitting.\n",
    "Fez-se o fit aos dados de treino e representaram-se as várias importâncias percentuais num gráfico de barras. Daqui, verificou-se que os parâmetros com mais importância são o L_sym, o K_sym e o K_sat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini Importance ou Mean Decrease in Impurity (MDI)\n",
    "#número de vezes que a feature é usada para dar split a um nó, tendo em conta o numero de amostras que divide.\n",
    "#Calcula a importância de cada parâmetro como a soma do número de divisões, splits, (no total das trees) \n",
    "#que incluem esse parâmetro, proporcionalmente ao número de amostras que esse parâmetro divide.\n",
    "#A diminuição da node impurity é somada e é feita a média pelo total das trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e0d2b3b22591>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#divisão com 25% dos dados para teste\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#visualização dados treino\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dados' is not defined"
     ]
    }
   ],
   "source": [
    "# Traning model with all features \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#divisão com 25% dos dados para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(dados.iloc[:,:-1], dados.iloc[:,-1], test_size = 0.25, random_state = 0)\n",
    "\n",
    "#visualização dados treino e teste\n",
    "#X_train\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a normalização feita, vamos agora fazer de novo um split, através da função train_test_split, onde 75% dos dados serão armazenados como dados de treino e o resto como dados de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K_sat</th>\n",
       "      <th>Q_sat</th>\n",
       "      <th>Z_sat</th>\n",
       "      <th>E_sym</th>\n",
       "      <th>L_sym</th>\n",
       "      <th>K_sym</th>\n",
       "      <th>Q_sym</th>\n",
       "      <th>Z_sym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>249.035799</td>\n",
       "      <td>36.277868</td>\n",
       "      <td>-121.881204</td>\n",
       "      <td>28.611336</td>\n",
       "      <td>40.239254</td>\n",
       "      <td>-88.252165</td>\n",
       "      <td>361.094335</td>\n",
       "      <td>-354.110257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>229.930362</td>\n",
       "      <td>-121.067426</td>\n",
       "      <td>28.800788</td>\n",
       "      <td>33.261380</td>\n",
       "      <td>76.097753</td>\n",
       "      <td>36.054762</td>\n",
       "      <td>-343.860441</td>\n",
       "      <td>389.311071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>255.555618</td>\n",
       "      <td>-7.572342</td>\n",
       "      <td>-69.231639</td>\n",
       "      <td>31.302686</td>\n",
       "      <td>65.241391</td>\n",
       "      <td>-91.390823</td>\n",
       "      <td>195.938899</td>\n",
       "      <td>241.646737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8198</th>\n",
       "      <td>225.028325</td>\n",
       "      <td>27.504570</td>\n",
       "      <td>-139.449905</td>\n",
       "      <td>33.287862</td>\n",
       "      <td>62.373814</td>\n",
       "      <td>-109.546580</td>\n",
       "      <td>507.318291</td>\n",
       "      <td>-658.409990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31403</th>\n",
       "      <td>218.881444</td>\n",
       "      <td>-114.240239</td>\n",
       "      <td>47.016619</td>\n",
       "      <td>32.157162</td>\n",
       "      <td>70.347108</td>\n",
       "      <td>75.626417</td>\n",
       "      <td>194.382888</td>\n",
       "      <td>-197.035278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13917</th>\n",
       "      <td>250.303843</td>\n",
       "      <td>-129.885165</td>\n",
       "      <td>40.851417</td>\n",
       "      <td>34.189569</td>\n",
       "      <td>68.994352</td>\n",
       "      <td>7.407975</td>\n",
       "      <td>405.125325</td>\n",
       "      <td>261.065879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27440</th>\n",
       "      <td>230.638782</td>\n",
       "      <td>-184.714014</td>\n",
       "      <td>176.274473</td>\n",
       "      <td>30.373797</td>\n",
       "      <td>41.109259</td>\n",
       "      <td>-65.560424</td>\n",
       "      <td>-73.176330</td>\n",
       "      <td>377.877310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11667</th>\n",
       "      <td>222.730845</td>\n",
       "      <td>-15.205561</td>\n",
       "      <td>-58.735474</td>\n",
       "      <td>34.336265</td>\n",
       "      <td>71.573601</td>\n",
       "      <td>76.199902</td>\n",
       "      <td>395.618007</td>\n",
       "      <td>231.665459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29616</th>\n",
       "      <td>242.715103</td>\n",
       "      <td>-76.925206</td>\n",
       "      <td>-35.502318</td>\n",
       "      <td>28.814337</td>\n",
       "      <td>46.360199</td>\n",
       "      <td>-145.802312</td>\n",
       "      <td>313.510577</td>\n",
       "      <td>-130.391396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39864</th>\n",
       "      <td>254.884807</td>\n",
       "      <td>-55.009799</td>\n",
       "      <td>-50.812273</td>\n",
       "      <td>32.406981</td>\n",
       "      <td>42.480204</td>\n",
       "      <td>-81.400112</td>\n",
       "      <td>620.544214</td>\n",
       "      <td>177.019534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>253.285716</td>\n",
       "      <td>-83.849868</td>\n",
       "      <td>-53.551834</td>\n",
       "      <td>32.714645</td>\n",
       "      <td>80.502581</td>\n",
       "      <td>-110.905890</td>\n",
       "      <td>585.241890</td>\n",
       "      <td>47.454997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34101</th>\n",
       "      <td>279.185718</td>\n",
       "      <td>-139.278948</td>\n",
       "      <td>48.960060</td>\n",
       "      <td>30.226866</td>\n",
       "      <td>55.563554</td>\n",
       "      <td>-133.169561</td>\n",
       "      <td>-43.590132</td>\n",
       "      <td>746.256357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131</th>\n",
       "      <td>240.804979</td>\n",
       "      <td>-118.550696</td>\n",
       "      <td>18.879398</td>\n",
       "      <td>33.439721</td>\n",
       "      <td>98.870737</td>\n",
       "      <td>-141.799774</td>\n",
       "      <td>519.568516</td>\n",
       "      <td>-663.958082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31896</th>\n",
       "      <td>219.769387</td>\n",
       "      <td>-73.884949</td>\n",
       "      <td>-42.188676</td>\n",
       "      <td>31.431425</td>\n",
       "      <td>42.832223</td>\n",
       "      <td>14.814255</td>\n",
       "      <td>377.505186</td>\n",
       "      <td>-228.232183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14655</th>\n",
       "      <td>227.168852</td>\n",
       "      <td>-76.042419</td>\n",
       "      <td>-32.646716</td>\n",
       "      <td>32.027914</td>\n",
       "      <td>51.576633</td>\n",
       "      <td>-166.213622</td>\n",
       "      <td>536.762593</td>\n",
       "      <td>1619.849434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14706</th>\n",
       "      <td>222.654346</td>\n",
       "      <td>182.775000</td>\n",
       "      <td>-290.939961</td>\n",
       "      <td>34.602724</td>\n",
       "      <td>34.835616</td>\n",
       "      <td>-107.174705</td>\n",
       "      <td>156.218650</td>\n",
       "      <td>156.196277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26870</th>\n",
       "      <td>213.682059</td>\n",
       "      <td>-44.872292</td>\n",
       "      <td>-48.765349</td>\n",
       "      <td>31.536594</td>\n",
       "      <td>56.113692</td>\n",
       "      <td>-197.509579</td>\n",
       "      <td>716.211892</td>\n",
       "      <td>-358.086439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28971</th>\n",
       "      <td>239.728210</td>\n",
       "      <td>-24.834508</td>\n",
       "      <td>-49.858540</td>\n",
       "      <td>32.925897</td>\n",
       "      <td>27.895413</td>\n",
       "      <td>-148.155267</td>\n",
       "      <td>320.011528</td>\n",
       "      <td>-75.794390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37394</th>\n",
       "      <td>263.812940</td>\n",
       "      <td>-171.216935</td>\n",
       "      <td>41.787831</td>\n",
       "      <td>32.632200</td>\n",
       "      <td>58.888904</td>\n",
       "      <td>-78.909864</td>\n",
       "      <td>446.320883</td>\n",
       "      <td>-177.403978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12434</th>\n",
       "      <td>245.575531</td>\n",
       "      <td>-175.220811</td>\n",
       "      <td>127.058130</td>\n",
       "      <td>31.649274</td>\n",
       "      <td>61.708107</td>\n",
       "      <td>-93.922768</td>\n",
       "      <td>-142.580286</td>\n",
       "      <td>583.926901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>243.447861</td>\n",
       "      <td>53.761564</td>\n",
       "      <td>-137.129327</td>\n",
       "      <td>29.434033</td>\n",
       "      <td>93.496198</td>\n",
       "      <td>-104.000050</td>\n",
       "      <td>5.383306</td>\n",
       "      <td>678.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>266.592616</td>\n",
       "      <td>-105.718509</td>\n",
       "      <td>-37.121266</td>\n",
       "      <td>34.250933</td>\n",
       "      <td>30.243767</td>\n",
       "      <td>72.543606</td>\n",
       "      <td>313.544496</td>\n",
       "      <td>1080.750446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>237.921629</td>\n",
       "      <td>-103.651843</td>\n",
       "      <td>6.416885</td>\n",
       "      <td>33.739827</td>\n",
       "      <td>75.654395</td>\n",
       "      <td>-153.966201</td>\n",
       "      <td>1056.554271</td>\n",
       "      <td>-718.880222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17971</th>\n",
       "      <td>221.360952</td>\n",
       "      <td>183.165738</td>\n",
       "      <td>-297.577855</td>\n",
       "      <td>33.001292</td>\n",
       "      <td>62.010726</td>\n",
       "      <td>-16.800164</td>\n",
       "      <td>293.062427</td>\n",
       "      <td>-243.300651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38813</th>\n",
       "      <td>257.090793</td>\n",
       "      <td>-53.247227</td>\n",
       "      <td>-72.082273</td>\n",
       "      <td>32.947593</td>\n",
       "      <td>83.434212</td>\n",
       "      <td>-140.696183</td>\n",
       "      <td>727.848954</td>\n",
       "      <td>-326.402166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>234.267046</td>\n",
       "      <td>111.747940</td>\n",
       "      <td>-275.819885</td>\n",
       "      <td>28.609046</td>\n",
       "      <td>54.798117</td>\n",
       "      <td>-41.806310</td>\n",
       "      <td>423.021958</td>\n",
       "      <td>-635.354116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14673</th>\n",
       "      <td>212.598527</td>\n",
       "      <td>48.451180</td>\n",
       "      <td>-167.031194</td>\n",
       "      <td>32.768136</td>\n",
       "      <td>65.494855</td>\n",
       "      <td>-98.760973</td>\n",
       "      <td>370.888544</td>\n",
       "      <td>163.159771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34932</th>\n",
       "      <td>239.991807</td>\n",
       "      <td>2.928981</td>\n",
       "      <td>-89.496328</td>\n",
       "      <td>37.200554</td>\n",
       "      <td>50.008892</td>\n",
       "      <td>42.944450</td>\n",
       "      <td>1005.079179</td>\n",
       "      <td>719.871634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26354</th>\n",
       "      <td>224.321218</td>\n",
       "      <td>-85.558691</td>\n",
       "      <td>-14.674312</td>\n",
       "      <td>30.335029</td>\n",
       "      <td>80.581247</td>\n",
       "      <td>35.549914</td>\n",
       "      <td>146.599847</td>\n",
       "      <td>703.355776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12181</th>\n",
       "      <td>235.473189</td>\n",
       "      <td>-151.702094</td>\n",
       "      <td>56.623423</td>\n",
       "      <td>32.039492</td>\n",
       "      <td>73.270371</td>\n",
       "      <td>-53.955670</td>\n",
       "      <td>342.947525</td>\n",
       "      <td>682.063614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17121</th>\n",
       "      <td>237.018893</td>\n",
       "      <td>2.048907</td>\n",
       "      <td>-126.662289</td>\n",
       "      <td>32.830255</td>\n",
       "      <td>63.777286</td>\n",
       "      <td>-63.430771</td>\n",
       "      <td>340.578560</td>\n",
       "      <td>125.013514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32042</th>\n",
       "      <td>235.484793</td>\n",
       "      <td>25.948530</td>\n",
       "      <td>-103.553532</td>\n",
       "      <td>27.439560</td>\n",
       "      <td>46.100835</td>\n",
       "      <td>39.062786</td>\n",
       "      <td>26.013380</td>\n",
       "      <td>508.867658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25767</th>\n",
       "      <td>205.656643</td>\n",
       "      <td>-70.311615</td>\n",
       "      <td>-10.015706</td>\n",
       "      <td>33.060947</td>\n",
       "      <td>66.649417</td>\n",
       "      <td>-67.531897</td>\n",
       "      <td>567.467861</td>\n",
       "      <td>1051.845097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>245.435304</td>\n",
       "      <td>-69.086189</td>\n",
       "      <td>-72.997804</td>\n",
       "      <td>32.043500</td>\n",
       "      <td>65.436745</td>\n",
       "      <td>7.604678</td>\n",
       "      <td>506.134244</td>\n",
       "      <td>-238.001970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>243.516871</td>\n",
       "      <td>-171.481366</td>\n",
       "      <td>38.139509</td>\n",
       "      <td>33.441636</td>\n",
       "      <td>88.513337</td>\n",
       "      <td>-49.294253</td>\n",
       "      <td>8.883797</td>\n",
       "      <td>158.976312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9656</th>\n",
       "      <td>243.994218</td>\n",
       "      <td>20.077873</td>\n",
       "      <td>-78.536741</td>\n",
       "      <td>30.206405</td>\n",
       "      <td>51.236777</td>\n",
       "      <td>-126.835267</td>\n",
       "      <td>111.855229</td>\n",
       "      <td>712.188053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29451</th>\n",
       "      <td>240.516241</td>\n",
       "      <td>-132.989464</td>\n",
       "      <td>56.606676</td>\n",
       "      <td>32.119670</td>\n",
       "      <td>44.177527</td>\n",
       "      <td>-81.365824</td>\n",
       "      <td>12.955483</td>\n",
       "      <td>790.628198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29331</th>\n",
       "      <td>221.402375</td>\n",
       "      <td>-142.336947</td>\n",
       "      <td>119.511933</td>\n",
       "      <td>31.849900</td>\n",
       "      <td>47.484498</td>\n",
       "      <td>-179.944576</td>\n",
       "      <td>181.695179</td>\n",
       "      <td>317.047807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>202.927554</td>\n",
       "      <td>73.714986</td>\n",
       "      <td>-180.491197</td>\n",
       "      <td>33.680580</td>\n",
       "      <td>68.074594</td>\n",
       "      <td>-136.771741</td>\n",
       "      <td>880.602044</td>\n",
       "      <td>1267.502227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33305</th>\n",
       "      <td>234.695786</td>\n",
       "      <td>16.357619</td>\n",
       "      <td>-87.566277</td>\n",
       "      <td>30.033634</td>\n",
       "      <td>74.628830</td>\n",
       "      <td>-58.047318</td>\n",
       "      <td>36.845672</td>\n",
       "      <td>514.674791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7114</th>\n",
       "      <td>222.453370</td>\n",
       "      <td>54.777579</td>\n",
       "      <td>-139.269261</td>\n",
       "      <td>33.197580</td>\n",
       "      <td>76.722173</td>\n",
       "      <td>-187.071154</td>\n",
       "      <td>105.199570</td>\n",
       "      <td>908.614900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31887</th>\n",
       "      <td>263.566118</td>\n",
       "      <td>-90.715028</td>\n",
       "      <td>-25.790990</td>\n",
       "      <td>32.019955</td>\n",
       "      <td>51.808946</td>\n",
       "      <td>-43.230136</td>\n",
       "      <td>349.870341</td>\n",
       "      <td>509.489347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36739</th>\n",
       "      <td>250.047522</td>\n",
       "      <td>11.082254</td>\n",
       "      <td>-71.081113</td>\n",
       "      <td>29.294055</td>\n",
       "      <td>80.373834</td>\n",
       "      <td>-105.548342</td>\n",
       "      <td>-48.808560</td>\n",
       "      <td>688.556989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31560</th>\n",
       "      <td>221.994344</td>\n",
       "      <td>-75.212419</td>\n",
       "      <td>-1.913636</td>\n",
       "      <td>33.276316</td>\n",
       "      <td>86.366887</td>\n",
       "      <td>80.605713</td>\n",
       "      <td>487.801419</td>\n",
       "      <td>-196.069244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12102</th>\n",
       "      <td>205.121854</td>\n",
       "      <td>-44.306593</td>\n",
       "      <td>-16.861843</td>\n",
       "      <td>29.508635</td>\n",
       "      <td>56.471058</td>\n",
       "      <td>-45.641956</td>\n",
       "      <td>107.456045</td>\n",
       "      <td>456.932685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>210.158770</td>\n",
       "      <td>212.799450</td>\n",
       "      <td>-340.350300</td>\n",
       "      <td>31.053923</td>\n",
       "      <td>49.859250</td>\n",
       "      <td>6.065586</td>\n",
       "      <td>338.529571</td>\n",
       "      <td>-460.713133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34547</th>\n",
       "      <td>215.005043</td>\n",
       "      <td>-100.811886</td>\n",
       "      <td>6.124204</td>\n",
       "      <td>33.199479</td>\n",
       "      <td>81.643616</td>\n",
       "      <td>-116.766008</td>\n",
       "      <td>512.162674</td>\n",
       "      <td>1238.781875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10988</th>\n",
       "      <td>239.002677</td>\n",
       "      <td>-15.508460</td>\n",
       "      <td>-102.456249</td>\n",
       "      <td>35.391284</td>\n",
       "      <td>75.422914</td>\n",
       "      <td>-217.138422</td>\n",
       "      <td>309.465820</td>\n",
       "      <td>284.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>234.323560</td>\n",
       "      <td>299.149678</td>\n",
       "      <td>-483.105131</td>\n",
       "      <td>32.731338</td>\n",
       "      <td>64.389357</td>\n",
       "      <td>-127.487505</td>\n",
       "      <td>244.554428</td>\n",
       "      <td>582.519667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36503</th>\n",
       "      <td>225.833399</td>\n",
       "      <td>37.282685</td>\n",
       "      <td>-94.167528</td>\n",
       "      <td>34.555786</td>\n",
       "      <td>79.738850</td>\n",
       "      <td>4.081376</td>\n",
       "      <td>-247.901833</td>\n",
       "      <td>701.394221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>212.201147</td>\n",
       "      <td>2.766169</td>\n",
       "      <td>-76.933576</td>\n",
       "      <td>31.343107</td>\n",
       "      <td>53.042184</td>\n",
       "      <td>-19.738778</td>\n",
       "      <td>121.023717</td>\n",
       "      <td>104.137929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17638</th>\n",
       "      <td>265.104379</td>\n",
       "      <td>8.272515</td>\n",
       "      <td>-86.861517</td>\n",
       "      <td>33.206627</td>\n",
       "      <td>39.394976</td>\n",
       "      <td>-77.191267</td>\n",
       "      <td>-195.239598</td>\n",
       "      <td>1039.836731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>209.481302</td>\n",
       "      <td>159.595297</td>\n",
       "      <td>-278.961478</td>\n",
       "      <td>31.481619</td>\n",
       "      <td>59.413731</td>\n",
       "      <td>-55.124871</td>\n",
       "      <td>9.599859</td>\n",
       "      <td>1010.238552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>253.124796</td>\n",
       "      <td>-91.645620</td>\n",
       "      <td>6.774505</td>\n",
       "      <td>32.748960</td>\n",
       "      <td>62.725729</td>\n",
       "      <td>-120.078310</td>\n",
       "      <td>734.563993</td>\n",
       "      <td>564.657848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21627</th>\n",
       "      <td>237.917545</td>\n",
       "      <td>125.127570</td>\n",
       "      <td>-208.790587</td>\n",
       "      <td>31.937721</td>\n",
       "      <td>74.389543</td>\n",
       "      <td>-187.470126</td>\n",
       "      <td>391.232029</td>\n",
       "      <td>-178.890738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30790</th>\n",
       "      <td>201.675339</td>\n",
       "      <td>-46.594292</td>\n",
       "      <td>-11.274272</td>\n",
       "      <td>33.844325</td>\n",
       "      <td>84.403376</td>\n",
       "      <td>-210.124111</td>\n",
       "      <td>1050.716859</td>\n",
       "      <td>964.101616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>257.019861</td>\n",
       "      <td>-123.219844</td>\n",
       "      <td>23.763979</td>\n",
       "      <td>29.886251</td>\n",
       "      <td>50.052373</td>\n",
       "      <td>-46.675208</td>\n",
       "      <td>227.376725</td>\n",
       "      <td>40.943514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17736</th>\n",
       "      <td>238.108565</td>\n",
       "      <td>-97.215011</td>\n",
       "      <td>6.031196</td>\n",
       "      <td>30.127420</td>\n",
       "      <td>54.702622</td>\n",
       "      <td>69.801906</td>\n",
       "      <td>-296.211860</td>\n",
       "      <td>1126.476985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>196.289137</td>\n",
       "      <td>57.131438</td>\n",
       "      <td>-158.994670</td>\n",
       "      <td>27.318927</td>\n",
       "      <td>42.940143</td>\n",
       "      <td>-63.951879</td>\n",
       "      <td>657.405100</td>\n",
       "      <td>-511.617525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>257.143109</td>\n",
       "      <td>-183.983589</td>\n",
       "      <td>55.327202</td>\n",
       "      <td>30.737800</td>\n",
       "      <td>50.575265</td>\n",
       "      <td>-69.266452</td>\n",
       "      <td>361.688458</td>\n",
       "      <td>123.054918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            K_sat       Q_sat       Z_sat      E_sym      L_sym       K_sym  \\\n",
       "12836  249.035799   36.277868 -121.881204  28.611336  40.239254  -88.252165   \n",
       "10913  229.930362 -121.067426   28.800788  33.261380  76.097753   36.054762   \n",
       "4214   255.555618   -7.572342  -69.231639  31.302686  65.241391  -91.390823   \n",
       "8198   225.028325   27.504570 -139.449905  33.287862  62.373814 -109.546580   \n",
       "31403  218.881444 -114.240239   47.016619  32.157162  70.347108   75.626417   \n",
       "13917  250.303843 -129.885165   40.851417  34.189569  68.994352    7.407975   \n",
       "27440  230.638782 -184.714014  176.274473  30.373797  41.109259  -65.560424   \n",
       "11667  222.730845  -15.205561  -58.735474  34.336265  71.573601   76.199902   \n",
       "29616  242.715103  -76.925206  -35.502318  28.814337  46.360199 -145.802312   \n",
       "39864  254.884807  -55.009799  -50.812273  32.406981  42.480204  -81.400112   \n",
       "7817   253.285716  -83.849868  -53.551834  32.714645  80.502581 -110.905890   \n",
       "34101  279.185718 -139.278948   48.960060  30.226866  55.563554 -133.169561   \n",
       "10131  240.804979 -118.550696   18.879398  33.439721  98.870737 -141.799774   \n",
       "31896  219.769387  -73.884949  -42.188676  31.431425  42.832223   14.814255   \n",
       "14655  227.168852  -76.042419  -32.646716  32.027914  51.576633 -166.213622   \n",
       "14706  222.654346  182.775000 -290.939961  34.602724  34.835616 -107.174705   \n",
       "26870  213.682059  -44.872292  -48.765349  31.536594  56.113692 -197.509579   \n",
       "28971  239.728210  -24.834508  -49.858540  32.925897  27.895413 -148.155267   \n",
       "37394  263.812940 -171.216935   41.787831  32.632200  58.888904  -78.909864   \n",
       "12434  245.575531 -175.220811  127.058130  31.649274  61.708107  -93.922768   \n",
       "5032   243.447861   53.761564 -137.129327  29.434033  93.496198 -104.000050   \n",
       "4070   266.592616 -105.718509  -37.121266  34.250933  30.243767   72.543606   \n",
       "9975   237.921629 -103.651843    6.416885  33.739827  75.654395 -153.966201   \n",
       "17971  221.360952  183.165738 -297.577855  33.001292  62.010726  -16.800164   \n",
       "38813  257.090793  -53.247227  -72.082273  32.947593  83.434212 -140.696183   \n",
       "5112   234.267046  111.747940 -275.819885  28.609046  54.798117  -41.806310   \n",
       "14673  212.598527   48.451180 -167.031194  32.768136  65.494855  -98.760973   \n",
       "34932  239.991807    2.928981  -89.496328  37.200554  50.008892   42.944450   \n",
       "26354  224.321218  -85.558691  -14.674312  30.335029  80.581247   35.549914   \n",
       "12181  235.473189 -151.702094   56.623423  32.039492  73.270371  -53.955670   \n",
       "...           ...         ...         ...        ...        ...         ...   \n",
       "17121  237.018893    2.048907 -126.662289  32.830255  63.777286  -63.430771   \n",
       "32042  235.484793   25.948530 -103.553532  27.439560  46.100835   39.062786   \n",
       "25767  205.656643  -70.311615  -10.015706  33.060947  66.649417  -67.531897   \n",
       "3998   245.435304  -69.086189  -72.997804  32.043500  65.436745    7.604678   \n",
       "1191   243.516871 -171.481366   38.139509  33.441636  88.513337  -49.294253   \n",
       "9656   243.994218   20.077873  -78.536741  30.206405  51.236777 -126.835267   \n",
       "29451  240.516241 -132.989464   56.606676  32.119670  44.177527  -81.365824   \n",
       "29331  221.402375 -142.336947  119.511933  31.849900  47.484498 -179.944576   \n",
       "10544  202.927554   73.714986 -180.491197  33.680580  68.074594 -136.771741   \n",
       "33305  234.695786   16.357619  -87.566277  30.033634  74.628830  -58.047318   \n",
       "7114   222.453370   54.777579 -139.269261  33.197580  76.722173 -187.071154   \n",
       "31887  263.566118  -90.715028  -25.790990  32.019955  51.808946  -43.230136   \n",
       "36739  250.047522   11.082254  -71.081113  29.294055  80.373834 -105.548342   \n",
       "31560  221.994344  -75.212419   -1.913636  33.276316  86.366887   80.605713   \n",
       "12102  205.121854  -44.306593  -16.861843  29.508635  56.471058  -45.641956   \n",
       "13318  210.158770  212.799450 -340.350300  31.053923  49.859250    6.065586   \n",
       "34547  215.005043 -100.811886    6.124204  33.199479  81.643616 -116.766008   \n",
       "10988  239.002677  -15.508460 -102.456249  35.391284  75.422914 -217.138422   \n",
       "6229   234.323560  299.149678 -483.105131  32.731338  64.389357 -127.487505   \n",
       "36503  225.833399   37.282685  -94.167528  34.555786  79.738850    4.081376   \n",
       "3678   212.201147    2.766169  -76.933576  31.343107  53.042184  -19.738778   \n",
       "17638  265.104379    8.272515  -86.861517  33.206627  39.394976  -77.191267   \n",
       "12427  209.481302  159.595297 -278.961478  31.481619  59.413731  -55.124871   \n",
       "10176  253.124796  -91.645620    6.774505  32.748960  62.725729 -120.078310   \n",
       "21627  237.917545  125.127570 -208.790587  31.937721  74.389543 -187.470126   \n",
       "30790  201.675339  -46.594292  -11.274272  33.844325  84.403376 -210.124111   \n",
       "5690   257.019861 -123.219844   23.763979  29.886251  50.052373  -46.675208   \n",
       "17736  238.108565  -97.215011    6.031196  30.127420  54.702622   69.801906   \n",
       "12098  196.289137   57.131438 -158.994670  27.318927  42.940143  -63.951879   \n",
       "5315   257.143109 -183.983589   55.327202  30.737800  50.575265  -69.266452   \n",
       "\n",
       "             Q_sym        Z_sym  \n",
       "12836   361.094335  -354.110257  \n",
       "10913  -343.860441   389.311071  \n",
       "4214    195.938899   241.646737  \n",
       "8198    507.318291  -658.409990  \n",
       "31403   194.382888  -197.035278  \n",
       "13917   405.125325   261.065879  \n",
       "27440   -73.176330   377.877310  \n",
       "11667   395.618007   231.665459  \n",
       "29616   313.510577  -130.391396  \n",
       "39864   620.544214   177.019534  \n",
       "7817    585.241890    47.454997  \n",
       "34101   -43.590132   746.256357  \n",
       "10131   519.568516  -663.958082  \n",
       "31896   377.505186  -228.232183  \n",
       "14655   536.762593  1619.849434  \n",
       "14706   156.218650   156.196277  \n",
       "26870   716.211892  -358.086439  \n",
       "28971   320.011528   -75.794390  \n",
       "37394   446.320883  -177.403978  \n",
       "12434  -142.580286   583.926901  \n",
       "5032      5.383306   678.822222  \n",
       "4070    313.544496  1080.750446  \n",
       "9975   1056.554271  -718.880222  \n",
       "17971   293.062427  -243.300651  \n",
       "38813   727.848954  -326.402166  \n",
       "5112    423.021958  -635.354116  \n",
       "14673   370.888544   163.159771  \n",
       "34932  1005.079179   719.871634  \n",
       "26354   146.599847   703.355776  \n",
       "12181   342.947525   682.063614  \n",
       "...            ...          ...  \n",
       "17121   340.578560   125.013514  \n",
       "32042    26.013380   508.867658  \n",
       "25767   567.467861  1051.845097  \n",
       "3998    506.134244  -238.001970  \n",
       "1191      8.883797   158.976312  \n",
       "9656    111.855229   712.188053  \n",
       "29451    12.955483   790.628198  \n",
       "29331   181.695179   317.047807  \n",
       "10544   880.602044  1267.502227  \n",
       "33305    36.845672   514.674791  \n",
       "7114    105.199570   908.614900  \n",
       "31887   349.870341   509.489347  \n",
       "36739   -48.808560   688.556989  \n",
       "31560   487.801419  -196.069244  \n",
       "12102   107.456045   456.932685  \n",
       "13318   338.529571  -460.713133  \n",
       "34547   512.162674  1238.781875  \n",
       "10988   309.465820   284.179600  \n",
       "6229    244.554428   582.519667  \n",
       "36503  -247.901833   701.394221  \n",
       "3678    121.023717   104.137929  \n",
       "17638  -195.239598  1039.836731  \n",
       "12427     9.599859  1010.238552  \n",
       "10176   734.563993   564.657848  \n",
       "21627   391.232029  -178.890738  \n",
       "30790  1050.716859   964.101616  \n",
       "5690    227.376725    40.943514  \n",
       "17736  -296.211860  1126.476985  \n",
       "12098   657.405100  -511.617525  \n",
       "5315    361.688458   123.054918  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dados teste\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999667489995"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#implementação do modelo decision tree e fit ao conjunto de dados\n",
    "d_tree = DecisionTreeRegressor()\n",
    "\n",
    "#ajusta as variáveis independentes às variáveis dependentes\n",
    "d_tree.fit(X_train,y_train)\n",
    "\n",
    "#avaliação do modelo de regressão - dados de treino\n",
    "d_tree.score(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, estando em condições de construir a decision tree. Implementado o modelo, podemos ajustar os dados de treino, as variáveis independentes, à decision tree. A seguir, calculou-se o \"score\", a pontuação, deste modelo de regressão aplicado aos dados de treino e o \"score\" deste modelo de regressão aplicado aos dados de teste. A pontuação do modelo será a precisão média face aos dados de teste ou treino, respetivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8828545789648694"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#avaliação do modelo de regressão - dados de teste\n",
    "d_tree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a54e9723c8>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "#seaborn é outra libraria de Python baseada em matplotlib, de visualização de dados estatísticos. Mais avançada.\n",
    " \n",
    "prediction_test = d_tree.predict(X_test)\n",
    "\n",
    "#diferença entre R10 registado e previsto\n",
    "sns.distplot(y_test-prediction_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a previsão realizada, vamos agora visualizar se os dados previstos para o raio seguem uma distribuição semelhante ao dos dados registados do raio. Utilizando a library seaborn, fazemos o plot da distribuiçã da diferença de valores dos dados do raio e dos dados previstos. Como se verifica na figura, a distribuição é bastante coincidente com a curva, o que nos diz que o intervalo de valores previstos é próximo do intervalo de valores registados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#com distribuição de pontos\n",
    "n_samples_train = len(y_train)\n",
    "n_samples_test = len(y_test)\n",
    "\n",
    "prediction_train = d_tree.predict(X_train)\n",
    "\n",
    "plt.plot([12, 13],[12, 13])\n",
    "\n",
    "plt.scatter(y_test,prediction_test)\n",
    "plt.scatter(y_train,prediction_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noutra perspetiva, podemos analisar num gráfico de distribuição de pontos que, representando os valores dos dados de previsão de teste em função dos raios verdadeiros de teste e os valores dos dados de previsão de treino em função dos raios verdadeiros de treino, verifica-se que seguem aproximadamente uma reta de declive y=x. A aproximação poderia ser melhor se a amostra fosse superior, esta foi com 40000 dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f72cc5bbbb78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtuning_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#calculado abaixo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd_tree' is not defined"
     ]
    }
   ],
   "source": [
    "#Intervalo de valores para inicializar a hiperparametrização - tuning, calibração\n",
    "\n",
    "parameters = {\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5],\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuning_model = GridSearchCV(d_tree, param_grid = parameters, scoring = 'neg_mean_squared_error',cv = 5, verbose = 3)\n",
    "\n",
    "#cv splitter\n",
    "#estratégia de splitting, como as iterações decorrem, 3-fold, 5-fold\n",
    "\n",
    "#verbosity, quanto maior, mais mensagens serão mostradas\n",
    "#>1 : the computation time for each fold and parameter candidate is displayed;\n",
    "#>2 : the score is also displayed;\n",
    "#>3 : the fold and candidate parameter indexes are also displayed together with the starting time of the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, ao contrário de anteriormente, fez-se outra decision tree- No entanto, desta vez, calcularam-se os melhores parâmetros para o modelo a serem colocados na regressão, na função DecisionTreeRegressor. \n",
    "\n",
    "Para isto, utilizou-se um algoritmo de hiperparametrização, com o comando GridSearchCV para ajustar, calibrar os melhores valores das métricas do estimador (d_tree) usados para aplicar os métodos de fit e score. Estes parâmetros são optimizados através de uma procura exaustiva de cross-validation sob um conjunto de parâmetros definidos previamente numa lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para calcular quanto tempo o calclulo iterarivo dos parâmetros demorou \n",
    "\n",
    "def timer(start_time = None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour,temp_sec = divmod((datetime.now() - start_time).total_seconds(),3600)\n",
    "        tmin,tsec = divmod(temp_sec,60)\n",
    "        #print(thour,\":\",tmin,':',round(tsec,2))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para uma melhor avaliação do modelo, queremos também considerar a componente temporal, quanto tempo demora, de facto, o processo de hiperparametrização. Assim, construiu-se esta pequena função com o objetivo de calcular o tempo que o processo de procura das métricas demorou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados.iloc[:,:-1]\n",
    "y = dados.iloc[:,-1]\n",
    "\n",
    "#%%capture parameter\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = timer(None)\n",
    "\n",
    "tuning_model.fit(X,y)\n",
    "\n",
    "timer(start_time)\n",
    "\n",
    "# best hyperparameters \n",
    "tuning_model.best_params_\n",
    "\n",
    "#parameter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começou-se então o processo de cálculo iterativo de GridSearchCV, com um método de fit e \"score\", que, neste caso, será igual ao erro MSE negativo. Escolheu-se uma verbosity de 3 e cv splitter igual a 5. Cada iteração tem o seguinte formato:\n",
    "\n",
    "[CV]  max_depth=12, max_features=None, max_leaf_nodes=90, min_samples_leaf=10, min_weight_fraction_leaf=0.5, splitter=random, score=-0.05489630765589389, total=0.0s\n",
    "\n",
    "Após 76.4min, o processo de procura terminou, tendo resultado os seguintes parâmetros:\n",
    "\n",
    "d_tree_tuned = DecisionTreeRegressor(max_depth = 5,\n",
    "                                         max_features = None,\n",
    "                                         max_leaf_nodes = 70,\n",
    "                                         min_samples_leaf = 10,\n",
    "                                         min_weight_fraction_leaf = 0.1,\n",
    "                                         splitter = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree_tuned = DecisionTreeRegressor(max_depth = 5,\n",
    "                                         max_features = None,\n",
    "                                         max_leaf_nodes = 70,\n",
    "                                         min_samples_leaf = 10,\n",
    "                                         min_weight_fraction_leaf = 0.1,\n",
    "                                         splitter = 'best')\n",
    "\n",
    "\n",
    "\n",
    "#outras tentativas\n",
    "#d_tree_tuned = DecisionTreeRegressor(max_depth = 9,\n",
    "                                         #max_features = None,\n",
    "                                         #max_leaf_nodes = 60,\n",
    "                                         #min_samples_leaf = 3,\n",
    "                                         #min_weight_fraction_leaf = 0.1,\n",
    "                                         #splitter = 'best')\n",
    "\n",
    "\n",
    "#d_tree_tuned = DecisionTreeRegressor(max_depth = 3,\n",
    "                                         #max_features = 'log2',\n",
    "                                         #max_leaf_nodes = 80,\n",
    "                                         #min_samples_leaf = 2,\n",
    "                                         #min_weight_fraction_leaf = 0.1,\n",
    "                                         #splitter = 'best')\n",
    "\n",
    "#c/ 3 fold\n",
    "#d_tree_tuned = DecisionTreeRegressor(max_depth = 11,\n",
    "                                         #max_features = None,\n",
    "                                         #max_leaf_nodes = 20,\n",
    "                                         #min_samples_leaf = 4,\n",
    "                                         #min_weight_fraction_leaf = 0.1,\n",
    "                                         #splitter = 'random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando os valores acima calculados, procedeu-se então à nova regressão, com as métricas calibradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_tree_tuned.fit(X_train,y_train)\n",
    "\n",
    "tuned_prediction_test = d_tree_tuned.predict(X_test)\n",
    "tuned_prediction_train = d_tree_tuned.predict(X_train)\n",
    "\n",
    "plt.scatter(y_test,tuned_prediction_test)\n",
    "plt.scatter(y_train,tuned_prediction_train)\n",
    "\n",
    "#pk é que estão dispostos numa linha horizontal?\n",
    "#de facto, o arranjo dos dados previstos neste modelo está mais próximo do de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pondo em prática o modelo de regressão mais uma vez, construiu-se outra decision tree, com as novas métricas e ajustaram-se novamente os dados de treino, as variáveis independentes, à decision tree calibrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Resultados do modelo com parâmetros ajustados \n",
    "\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import r2_score\n",
    "\n",
    "#root-mean-square error (RMSE)\n",
    "#print(np.sqrt(mean_squared_error(y_test,pred_test_tree)))\n",
    "\n",
    "#RMSE and R-squared value for regression tree on testing data\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test,tuned_prediction_test))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, tuned_prediction_test))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, tuned_prediction_test)))\n",
    "#print(r2_score(y_test, tuned_prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, calcularam-se os erros relacionados com o modelo sem parâmetros ajustados e o modelo com parâmetros ajustados.\n",
    "O erro mais importante, que merece mais consideração, é o RMSE, ou seja, o root mean squared error. Este erro é uma forma de medir a diferença entre os valores previstos por um modelo e os valores verdadeiros registados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resultados do modelo sem parâmetros ajustados\n",
    "\n",
    "#RMSE and R-squared value for regression tree on testing data\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test,prediction_test))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction_test))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversed_xtrain = sc.inverse_transform(X_train)\n",
    "inversed_xtest = sc.inverse_transform(X_test)\n",
    "#print(inversed_xtrain)\n",
    "#print(inversed_xtest)\n",
    "\n",
    "#R SQUARED\n",
    "#avalia a dispersão de valores à volta da linha de regressão\n",
    "#para o mesmo conjunto de dados, um R-squared elevado quer dizer que as diferenças entre os dados observados e \n",
    "#ajustados são pequenas\n",
    "\n",
    "d_tree_tuned.score(X_train,y_train)\n",
    "#0.47821531082460156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paralelamente, calculou-se os valores finais do \"score\" do modelo com parâmetros ajustados, para comparar com o \"score\" do modelo anterior. Para isto, teve que se inverter a normalização feita no início do programa, pois o cálculo destas métricas finais não precisa da normalização das unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree_tuned.score(X_test,y_test)\n",
    "#0.26258152207530394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking difference between labled y and predicted y\n",
    "sns.distplot(y_test-tuned_prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, visualizaram-se os dados previstos para o raio novamente, mas com as métricas da regressão calibradas. Verifica-se que seguem uma distribuição semelhante ao dos dados registados do raio. Utilizando a library seaborn, fez-se novemente o plot da distribuição da diferença de valores dos dados do raio e dos dados previstos. Como se verifica na figura, a distribuição é bastante coincidente com a curva, o que nos diz que o intervalo de valores previstos é próximo do intervalo de valores registados mais uma vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
